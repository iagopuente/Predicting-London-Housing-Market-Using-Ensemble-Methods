---
title: 'Session 10: Data Science Capstone Project'
author: "Dr Kanishka Bhattacharya"
date: "`r Sys.Date()`"
output: 
    html_document:
      number_sections: true
      highlight: haddock
      theme: spacelab
      toc: yes
      toc_depth: 2
      toc_float:
        collapsed: false
---

```{r setup, include=FALSE}
# Setting up R Markdown options for clean and clear outputs
knitr::opts_chunk$set(echo = TRUE)
```

<style>
div.navy1 { background-color:#686868; border-radius: 5px; padding: 20px; border-style: groove; color: #ffffff;}

</style>

```{r, load_libraries, include = FALSE}
# Checking and loading required packages. Installs them if not present.
if(!is.element("tidyverse", installed.packages()[,1]))
{  install.packages("tidyverse", repos = "http://cran.us.r-project.org")}
if(!is.element("Hmisc", installed.packages()[,1]))
{  install.packages("Hmisc", repos = "http://cran.us.r-project.org")} #package for data summary using `describe`
if(!is.element("ggplot2", installed.packages()[,1]))
{  install.packages("ggplot2", repos = "http://cran.us.r-project.org")} #package for plots
if(!is.element("ggthemes", installed.packages()[,1]))
{  install.packages("ggthemes", repos = "http://cran.us.r-project.org")} #package to make fancier ggplots
if(!is.element("janitor", installed.packages()[,1]))
{ install.packages("janitor", repos = "http://cran.us.r-project.org")} #package to visualize results of machine learning tools
if(!is.element("rpart.plot", installed.packages()[,1]))
{  install.packages("rpart.plot", repos = "http://cran.us.r-project.org")} #package to visualize trees
if (!requireNamespace("caretEnsemble", quietly = TRUE)) {
  install.packages("caretEnsemble", repos = "http://cran.us.r-project.org")
}

# Loading all libraries
library(rpart.plot)
library(caret)
library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate)
library(janitor) # clean_names()
library(Hmisc)
library(gbm)
library(caretEnsemble)
```

# Introduction and learning objectives

::: navy1
The purpose of this exercise is to build an estimation engine to guide investment decisions in London house market. You will first build machine learning algorithms (and tune them) to estimate the house prices given variety of information about each property. Then, using your algorithm, you will choose 200 houses to invest in out of about 2000 houses on the market at the moment.

<b>Learning objectives</b>

<ol type="i">

<li>Using different data mining algorithms for prediction.</li>

<li>Dealing with large data sets</li>

<li>Tuning data mining algorithms</li>

<li>Interpreting data mining algorithms and deducing importance of variables</li>

<li>Using results of data mining algorithms to make business decisions</li>

</ol>
:::

# Load data

There are two sets of data, i) training data that has the actual prices ii) out of sample data that has the asking prices. Load both data sets.

Make sure you understand what information each column contains. Note that not all information provided might be useful in predicting house prices, but do not make any assumptions before you decide what information you use in your prediction algorithms.

```{r read-investigate}
# Load training and test datasets
london_house_prices_2019_training<-read.csv("training_data_assignment_with_prices.csv")
london_house_prices_2019_out_of_sample<-read.csv("test_data_assignment.csv")

# Fix data types for both datasets
# Convert 'date' columns to Date format
london_house_prices_2019_training <- london_house_prices_2019_training %>% mutate(date=as.Date(date))
london_house_prices_2019_out_of_sample<-london_house_prices_2019_out_of_sample %>% mutate(date=as.Date(date))
# Convert character columns to factors for compatibility with ML algorithms
london_house_prices_2019_training <- london_house_prices_2019_training %>% mutate_if(is.character,as.factor)
london_house_prices_2019_out_of_sample<-london_house_prices_2019_out_of_sample %>% mutate_if(is.character,as.factor)

# Examine structure of the datasets
str(london_house_prices_2019_training)
str(london_house_prices_2019_out_of_sample)
```

```{r split the price data to training and testing}
# Splitting data into training and testing subsets (75% train, 25% test)
library(rsample)
set.seed(123) # Set seed for reproducibility of data splitting
train_test_split <- initial_split(london_house_prices_2019_training, prop = 0.75)
# Creating training and testing datasets
train_data <- training(train_test_split)
test_data <- testing(train_test_split)
```

# Visualize data

Visualize and examine the data. What plots could be useful here? What do you learn from these visualizations?

```{r visualize}
# Visualizing the distribution of house prices
library(ggplot2)
ggplot(london_house_prices_2019_training, aes(x = price)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of House Prices", x = "Price", y = "Frequency")

# Scatter plot of house prices vs. distance to nearest station
ggplot(london_house_prices_2019_training, aes(x = distance_to_station, y = price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", col = "red") +
  theme_minimal() +
  labs(title = "Price vs. Distance to Station", x = "Distance to Station", y = "Price")
```

Estimate a correlation table between prices and other continuous variables. What do you glean from the correlation table?

```{r, correlation table, warning=FALSE, message=FALSE}
# Estimate a correlation table between prices and other continuous variables
# This helps identify relationships between price and other numerical features
# The GGally::ggcorr function generates a heatmap to visualize these correlations
library("GGally")
london_house_prices_2019_training %>% 
  select(-ID) %>% #keep Y variable last
  ggcorr(method = c("pairwise", "pearson"), layout.exp = 2,label_round=2, label = TRUE,label_size = 2,hjust = 1,nbreaks = 5,size = 2,angle = -20)

```

# Fit a linear regression model

To help you get started I build a linear regression model below. I chose a subset of the features with no particular goal. You can (and should) add more variables and/or choose variable selection methods if you want.

```{r LR model}
#Define control variables
control <- trainControl (
    method="cv",
    number=5,
    verboseIter=TRUE) #by setting this to true the model will report its progress after each estimation

# Define control settings for cross-validation during training
control <- trainControl(
  method = "cv",
  number = 5,
  verboseIter = TRUE,
  savePredictions = "all" # Required for stacking
)

# Train a linear regression model using selected features
set.seed(123) # Set seed for reproducibility of linear regression training
model1_lm <- train(
  price ~ distance_to_station + water_company + property_type + whether_old_or_new + freehold_or_leasehold + latitude + longitude,
  data = train_data,
  method = "lm",
  trControl = control
)

# Summarize the linear regression results to examine coefficients and fit
summary(model1_lm)
```

```{r}
# Evaluate variable importance in the linear regression model
importance <- varImp(model1_lm, scale=TRUE)
plot(importance)
```

## Predict the values in testing and out of sample data

Below I use the predict function to test the performance of the model in testing data and summarize the performance of the linear regression model. How can you measure the quality of your predictions?

```{r}
# Predict prices in the testing dataset
predictions <- predict(model1_lm,test_data)

# Calculate evaluation metrics: RMSE and R-squared
lr_results<-data.frame(  RMSE = RMSE(predictions, test_data$price), 
                            Rsquare = R2(predictions, test_data$price))
                            
lr_results                         

# Predict prices for the out-of-sample dataset
predictions_oos <- predict(model1_lm,london_house_prices_2019_out_of_sample)
```

# Fit a tree model

Next I fit a tree model using the same subset of features. Again you can (and should) add more variables and tune the parameter of your tree to find a better fit.

Compare the performance of the linear regression model with the tree model; which one performs better? Why do you think that is the case?

```{r tree model}
# Train a decision tree model
set.seed(123) # Set seed for reproducibility of decision tree training
model2_tree <- train(
  price ~ distance_to_station + water_company + property_type + whether_old_or_new + latitude + longitude,
  data = train_data,
  method = "rpart",
  trControl = control,
  tuneLength = 10 # Explore 10 hyperparameter settings for the tree
)

# Display results of the trained tree model
model2_tree$results

# Visualize the final decision tree
rpart.plot(model2_tree$finalModel)

# Evaluate variable importance for the tree model
importance <- varImp(model2_tree, scale = TRUE)
plot(importance)
```

# Other algorithms

Use at least two other algorithms to predict prices. Don't forget to tune the parameters of these algorithms. And then compare the performances of your algorithms to linear regression and trees.

# Gradient Boosting

```{r}
# Train a Gradient Boosting Machine (GBM) model
set.seed(123) # Set seed for reproducibility of GBM training
model3_gbm <- train(
  price ~ distance_to_station + water_company + property_type + whether_old_or_new + latitude + longitude, # Selected features
  data = train_data, # Training data
  method = "gbm", # Specify GBM as the method
  trControl = control, # Use defined cross-validation settings
  verbose = FALSE # Suppress detailed training output
)

# Summarize the results of the GBM model
library(gbm)
summary(model3_gbm)

# Evaluate the importance of variables in the GBM model
importance <- varImp(model3_gbm, scale = TRUE) # Scaled variable importance
plot(importance) # Visualize variable importance
```

# Random Forest

```{r}
# Train a Random Forest model
set.seed(123) # Set seed for reproducibility of Random Forest training
model4_rf <- train(
  price ~ distance_to_station + water_company + property_type + whether_old_or_new + latitude + longitude, # Selected features
  data = train_data, # Training data
  method = "rf", # Specify Random Forest as the method
  trControl = control, # Use defined cross-validation settings
  tuneGrid = expand.grid(.mtry = c(2, 4, 6)), # Test different values of 'mtry' (features considered at each split)
  ntree = 50 # Number of trees in the forest
)

# Summarize the results of the Random Forest model
summary(model4_rf)

# Evaluate the importance of variables in the Random Forest model
importance <- varImp(model4_rf, scale = TRUE) # Scaled variable importance
plot(importance) # Visualize variable importance
```

# Stacking

Use stacking to ensemble your algorithms.

```{r,warning=FALSE,  message=FALSE }
# Combine individual models into a list for stacking
models <- list(
  lm = model1_lm, # Linear Regression
  tree = model2_tree, # Decision Tree
  gbm = model3_gbm, # Gradient Boosting Machine
  rf = model4_rf # Random Forest
)

# Define control settings for stacking
stack_control <- trainControl(
  method = "cv", # Cross-validation method
  number = 5, # 5-fold cross-validation
  savePredictions = "all", # Save all predictions for stacking
  verboseIter = TRUE # Show progress during training
)

# Train a stacked model with Logistic Regression as the meta-learner
set.seed(123) # Set seed for reproducibility of stacking
stacked_model <- caretStack(
  models, # List of models to stack
  method = "glm", # Meta-learner is a logistic regression
  trControl = stack_control # Cross-validation settings
)

# Evaluate the performance of the stacked model
summary(stacked_model) # Summarize the stacked model
```
```{r}
# Predict on testing data
stacked_predictions <- predict(stacked_model, test_data)
stacked_predictions <- stacked_predictions$pred

# Evaluate performance
stacked_results <- data.frame(
  RMSE = RMSE(stacked_predictions, test_data$price),
  Rsquare = R2(stacked_predictions, test_data$price)
)
print(stacked_results)

# Predict on out-of-sample data
london_house_prices_2019_out_of_sample$predicted_price <- predict(stacked_model, london_house_prices_2019_out_of_sample)
```

# Pick investments

In this section you should use the best algorithm you identified to choose 200 properties from the out of sample data.

```{r,warning=FALSE,  message=FALSE }
# Define the number of properties to choose
set.seed(123) # Set seed for reproducibility of investment selection
numchoose = 200

# Predict house prices in out-of-sample data using the best-performing model (e.g., GBM)
oos <- london_house_prices_2019_out_of_sample # Out-of-sample dataset
oos$predicted_price <- predict(model3_gbm, oos) # Replace 'model3_gbm' with the chosen model if different

# Check if the 'asking_price' column exists to calculate profit
if (!"asking_price" %in% colnames(oos)) {
  stop("Column 'asking_price' is missing in the out-of-sample data.") # Ensure integrity of data
}

# Calculate profit margin for each property
oos$profit <- (oos$predicted_price - oos$asking_price) / oos$asking_price # Profit formula

# Sort properties by profit margin in descending order
oos <- oos %>% arrange(desc(profit))

# Select the top 200 investments based on profit margin
selected_properties <- oos %>% 
  slice(1:numchoose) %>% # Choose top 200 profitable properties
  mutate(buy = 1) # Mark them as selected for purchase

# Assign 'buy = 0' to all other properties
oos <- oos %>% 
  mutate(buy = ifelse(ID %in% selected_properties$ID, 1, 0))

# Save the results to a CSV file for review and submission
write.csv(oos, "PuenteEsteban_Iago.csv", row.names = FALSE) # Save file with specified name
```
